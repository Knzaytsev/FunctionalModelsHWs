{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Предложите четыре стимула для враждебного NLI.\n",
    "\n",
    "Ресурс для справки: https://aclanthology.org/2020.acl-main.441/ (особенно, Table 1)\n",
    "\n",
    "Каждый стимул должен содержать:\n",
    "\n",
    "1. контекст\n",
    "2. гипотезу\n",
    "3. предлагаемый Вами лейбл отношения\n",
    "4. предположительную причину сложности приписывания лейбла алгоритмом\n",
    "5. лингвистическую аннотацию: какие языковые черты контекста приводят к сложности приписывания лейбла отношения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U05fYr70w2Hp"
   },
   "source": [
    "| Контекст | Гипотеза | Лейбл | Причина | Аннотация |\n",
    "|----------|----------|-------|---------|-----------|\n",
    "|Праляк, услышав решение суда,</br> заявил о своей невиновности и принял яд — цианистый калий.</br> В тот же день умер в больнице.|Праляк отравился цианидом и скончался в больнице|entailement|Модель может не знать синонимичных слов к </br>\"принял яд\" (отравился) и \"цианистый калий\" (цианид),</br> потому это может запутать её|Синонимы|\n",
    "|Распад Югославии — обобщённое название событий 1991—2008 годов,</br> в результате которых бывшая</br> Социалистическая Федеративная Республика Югославия (СФРЮ)</br> разделилась на шесть независимых стран и одно частично признанное государство.</br> Процесс распада государства берёт начало в 1991—1992 годах,</br> когда от него отделились четыре из шести республик</br> (Словения, Хорватия, Босния и Герцеговина и Македония).|Хорватия не отсоединялась от Югославии.|contradiction| Модель может не понять,</br> что распад и отсоединение - это синонимичные слова,</br> также используется отрицание (\"не отсоединялась\"),</br> которое указывает на противоречие,</br> но вместе с синонимом может запутать модель ещё сильнее| Синонимы, отрицание |\n",
    "|Процесс по делу Милошевича не был закончен,</br> так как подсудимый умер в тюрьме в Гааге в 2006 году,</br> согласно результатам вскрытия, от инфаркта миокарда.</br> Он был обнаружен тюремным персоналом</br> без признаков жизни на кровати в своей камере в Схевенингене.</br> Трибунал опроверг всякую ответственность за смерть Милошевича и заявил,</br> что он отказался взять прописанные лекарства и вместо этого лечил себя сам.</br> Согласно отчёту судьи, Милошевич умер между 7.30 и 8 часами утра.|Подсудимый умер мартовским утром в 2006 году|neutral|Модель может запутать указание на конкретный месяц,</br> также \"подсудимый\" может значит вообще любого подсудимого,</br> умершего в 2006 году в марте,</br> но при этом в тексте это слово используется,</br> что также может запутать модель |Время|\n",
    "|4 мая 1980 года Тито скончался в возрасте восьми десяти семи лет.</br> Пост президента был упразднён, а власть перешла в руки коллективного руководства,</br> которое, однако, очень быстро дискредитировало себя в глазах общества.|Бывший президент Югославии умер на 88 году жизни.|entailement|Для запутывания в стимуле</br> используется перевод числа в текст,</br> что возможно модель не умеет распознавать,</br> также используется</br> прилагательное бвыший и синоним скончался|Синонимы, числа|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Предложите четыре стимула для корпуса по комитменту для русского языка и соответствующую аннотацию. Стимулы должны содержать разные пропозициональные предикаты.\n",
    "\n",
    "Ресурсы для справки: https://semanticsarchive.net/Archive/Tg3ZGI2M/Marneffe.pdf; https://github.com/mcdm/CommitmentBank.\n",
    "\n",
    "Аннотация для каждого стимула:\n",
    "\n",
    "1. контекст (context, максимум 2 предложения или реплики до целевого предложения)\n",
    "2. целевое предложение (target, обратите внимание, что оно должно содержать оператор, отменяющий следствия (вопрос, отрицание, модальный глагол, или условный оператор), в сферу действия которого попадает пропозициональный предикат (бояться, подозревать, думать, знать, чувствовать, понимать, надеяться, забывать, обнаруживать, воображать))\n",
    "3. пропозициональный предикат (verb, например: бояться, подозревать, думать, знать, чувствовать, понимать, надеяться)\n",
    "4. оператор, отменяющий следствия (embedding: вопрос, отрицание, модальный глагол, условный оператор), в сферу действия которого попадает пропозициональный предикат\n",
    "5. источник (откуда добавленный контекст, например, НКРЯ или VK)\n",
    "6. Ваша оценка комитмента (как Вы оцениваете комитмент говорящего к содержанию комплемента пропозиционального глагола по шкале от -3 до +3 (+3/говорящий уверен, что комплемент истинен, 0/говорящий не уверен, что комплемент истинен или ложен, -3/говорящий уверен, что комплемент ложен))\n",
    "7. Ваш комментарий к стимулу и к Вашей оценке комитмента (что в стимуле интересного с точки зрения комитмента говорящего, есть ли в нём фактивный глагол и т.п.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "egQTRZ8W_qqa",
    "outputId": "98a0591b-eb14-4087-ae93-fa87c351d1be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uID</th>\n",
       "      <th>HitID</th>\n",
       "      <th>WorkerID</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Context</th>\n",
       "      <th>Target</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>ModalType</th>\n",
       "      <th>MatTense</th>\n",
       "      <th>MatSubjLemma</th>\n",
       "      <th>MatSubjPer</th>\n",
       "      <th>MatSubjNum</th>\n",
       "      <th>mean.noTarget</th>\n",
       "      <th>sd.noTarget</th>\n",
       "      <th>genre</th>\n",
       "      <th>factive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNC-1</td>\n",
       "      <td>3TKXBROM5TF22DT7M93MPUB6L0MIJ3</td>\n",
       "      <td>A2BA9Y6VGW6WS1</td>\n",
       "      <td>admit</td>\n",
       "      <td>2</td>\n",
       "      <td>Polly had to think quickly.</td>\n",
       "      <td>They were still close enough to shore for him ...</td>\n",
       "      <td>Polly was not an experienced ocean sailor</td>\n",
       "      <td>conditional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>future</td>\n",
       "      <td>she</td>\n",
       "      <td>third</td>\n",
       "      <td>singular</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>1.269296</td>\n",
       "      <td>BNC</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BNC-1</td>\n",
       "      <td>3TKXBROM5TF22DT7M93MPUB6L0MIJ3</td>\n",
       "      <td>A1945USNZHTROX</td>\n",
       "      <td>admit</td>\n",
       "      <td>3</td>\n",
       "      <td>Polly had to think quickly.</td>\n",
       "      <td>They were still close enough to shore for him ...</td>\n",
       "      <td>Polly was not an experienced ocean sailor</td>\n",
       "      <td>conditional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>future</td>\n",
       "      <td>she</td>\n",
       "      <td>third</td>\n",
       "      <td>singular</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>1.269296</td>\n",
       "      <td>BNC</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BNC-1</td>\n",
       "      <td>3TKXBROM5TF22DT7M93MPUB6L0MIJ3</td>\n",
       "      <td>A1F3P6N7BO9HBN</td>\n",
       "      <td>admit</td>\n",
       "      <td>3</td>\n",
       "      <td>Polly had to think quickly.</td>\n",
       "      <td>They were still close enough to shore for him ...</td>\n",
       "      <td>Polly was not an experienced ocean sailor</td>\n",
       "      <td>conditional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>future</td>\n",
       "      <td>she</td>\n",
       "      <td>third</td>\n",
       "      <td>singular</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>1.269296</td>\n",
       "      <td>BNC</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uID                           HitID        WorkerID   Verb  Answer  \\\n",
       "0  BNC-1  3TKXBROM5TF22DT7M93MPUB6L0MIJ3  A2BA9Y6VGW6WS1  admit       2   \n",
       "1  BNC-1  3TKXBROM5TF22DT7M93MPUB6L0MIJ3  A1945USNZHTROX  admit       3   \n",
       "2  BNC-1  3TKXBROM5TF22DT7M93MPUB6L0MIJ3  A1F3P6N7BO9HBN  admit       3   \n",
       "\n",
       "                       Context  \\\n",
       "0  Polly had to think quickly.   \n",
       "1  Polly had to think quickly.   \n",
       "2  Polly had to think quickly.   \n",
       "\n",
       "                                              Target  \\\n",
       "0  They were still close enough to shore for him ...   \n",
       "1  They were still close enough to shore for him ...   \n",
       "2  They were still close enough to shore for him ...   \n",
       "\n",
       "                                      Prompt    Embedding ModalType MatTense  \\\n",
       "0  Polly was not an experienced ocean sailor  conditional       NaN   future   \n",
       "1  Polly was not an experienced ocean sailor  conditional       NaN   future   \n",
       "2  Polly was not an experienced ocean sailor  conditional       NaN   future   \n",
       "\n",
       "  MatSubjLemma MatSubjPer MatSubjNum  mean.noTarget  sd.noTarget genre factive  \n",
       "0          she      third   singular      -0.111111     1.269296   BNC      no  \n",
       "1          she      third   singular      -0.111111     1.269296   BNC      no  \n",
       "2          she      third   singular      -0.111111     1.269296   BNC      no  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('CommitmentBank-All.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZ7wQ-xCBN--",
    "outputId": "7b62b1cb-f61a-4a56-816f-5f49360c9874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb: assume\n",
      "Context: I asked him in for a break. I liked that about him.\n",
      "Target: He never assumed the kettle was on or that I was free.\n",
      "Prompt: the kettle was on\n",
      "Embedding: negation\n",
      "Verb: assume\n",
      "Context: I asked him in for a break. I liked that about him.\n",
      "Target: He never assumed the kettle was on or that I was free.\n",
      "Prompt: the kettle was on\n",
      "Embedding: negation\n",
      "Verb: assume\n",
      "Context: I asked him in for a break. I liked that about him.\n",
      "Target: He never assumed the kettle was on or that I was free.\n",
      "Prompt: the kettle was on\n",
      "Embedding: negation\n"
     ]
    }
   ],
   "source": [
    "sub_df = df.loc[df['Embedding'] == 'negation']\n",
    "\n",
    "for i in range(0, len(sub_df.head(3))):\n",
    "  print('Verb: ' + sub_df.iloc[i, 3])\n",
    "  print('Context: ' + sub_df.iloc[i, 5])\n",
    "  print('Target: ' + sub_df.iloc[i, 6])\n",
    "  print('Prompt: ' + sub_df.iloc[i, 7])\n",
    "  print('Embedding: ' + sub_df.iloc[i, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6fU51Y9ySz8"
   },
   "source": [
    "| Контекст | Таргет | Предикат | Оператор | Источник | Оценка | Комментарий |\n",
    "|----------|--------|----------|----------|----------|--------|-------------|\n",
    "|― А кому верите ― Зюганову, Явлинскому \"медведям\",</br> Немцову, Жириновскому..| ― Я никому не верю.| верю | отрицание | НКРЯ |+3| По утвердительному ответу и словом \"никому\" чувствуется, что говорящий уверен в том, что он никому не верит\n",
    "| Политик отвергает и возможность возникновения проблем</br> от такого запрета у местных предпринимателей</br> и владельцев кафе и ресторанов.| «Абсолютно не думаю.</br> Конечно, продажа алкоголя — это существенная статья доходов,</br> но отсутствие алкоголя в долгосрочной перспективе приведет</br> к повышению расходов граждан по другим направлениям,</br> а именно на спорт, культурный отдых», — признался депутат.| думаю | отрицание | НКРЯ |-3| В стимуле интересно то, что уверенность в отрицательно комплементе определяется словом \"абсолютно\"\n",
    "| Я ищу его в поддержку себе ―</br> плясать и петь частушки в столь серьезном кругу</br> без поддержки как-то боязно. | (Почему я был уверен в его поддержке, надеюсь, понятно?!) | надеюсь | вопрос | НКРЯ |+2| Посредством использования знаков \"?!\" выражается уверенность в высказывании, но по моим ощущениям \"надеюсь\" в этом контексте всё равно не выражает полную уверенность\n",
    "| Всё-таки свои соображения к дискуссии</br> (если не помешаю вам Лилия, Alla? ) попытаюсь высказать. | Высказаться, конечно же, попытайтесь,</br> отчего ж не попытаться! А если Вам так захотелось</br> поплеваться в нашу сторону, то, боюсь,</br> слюны не хватит, Господин Хороший! | боюсь | условие | НКРЯ |+1| Скорее всего использование фразы \"в нашу сторону\" подразумевает какое-то большое количество человек, поэтому говорящий не совсем уверен, что пользователю хватит слюны поплеваться\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3\n",
    "Обычно пространство отношений разбивается на две (следствие, не-следствие), три (следствие, не-следствие, противоречие), или четыре (тождественность, включение, обратное включение, не-следствие) категории. Какой дизайн кажется Вам наиболее перспективным? Приведите лингвистические аргументы (с языковыми примерами) за (и, возможно, против) выбранной Вами опции. Что Вы думаете по поводу расширения наименований отношений, например, наподобие инвентаря лексических функций (https://ru.coursera.org/lecture/moscow-semantic-school/lieksichieskiie-funktsii-cGj17) или за счёт включения пресуппозициональных отношений, конверсациональных импликатур?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkuDSQrV-Dw4"
   },
   "source": [
    "На мой взгляд, наиболее перспективным дизайном будет тождественность, включение (обратное и прямое), не-следствие. Выбор обосновывается тем, что такие лейблы позволят впоследствии составлять различные отношения между понятиями в тексте, что приблизит модели к пониманию естественного языка. Так, например, с помощью тождественности модель сможет выделять различные синонимы (к примеру \"дом\" и \"жилище\"). Включение позволит определять объекты, которые либо образовывают класс, либо принадлежат конкретному классу. Например, \"кролик\" и \"животное\" имеют связь включения, при этом если \"животное\" будет находиться в контексте, а \"кролик\" в гипотезе, то лейбл будет обратным включением, в противном же случае это будет лейбл прямого включения. Стоит отметить, что с обратным включением может возникнуть такая проблема, что в высказывании с названием класса не всегда будет следовать какой-то объект класса. К примеру можно взять контекст \"Вчера мальчик на обед съел животное\" и гипотезу \"Мальчик съел кролика\". Здесь будет тяжело приписать обратное включение, ведь мальчик мог съесть не только кролика, но и, например, курицу. Ещё одна проблема заключается в том, что по мере увеличения лейблов приходится использовать и больше аннотаторов для верификации  лейблов (для трёх лейблов нужно больше трёх аннотаторов, для четырёх - больше четырёх и т.д.), поскольку только так можно достигнуть наиболее независимой оценки лейбла.\n",
    "\n",
    "\n",
    "Можно включить пресуппозиции и импликатуры, тогда область решаемых задач будет немного расширена. С помощью отношения пресуппозиции можно извлекать различные факты о мире или говорящем из высказывания. Если обучить на таких данных модель, то она будет выявлять различные паттерны в высказываниях и получать из них факты. Такая модель будет полезна для выявления следствий из высказываний, в которых не говорится явно о каком-то объекте. К примеру с помощью такой модели можно было бы поставить лейбл следствия в контексте \"Вася купил вчера тарелку\" и в гипотезе \"У Васи есть тарелка\". В целом то же самое можно сказать про импликатуры. Они так же, как и пресуппозиции, помогут получить факты о мире через высказывания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4\n",
    "Аннотация по комитменту говорящего включает в себя 7 лейблов (https://github.com/mcdm/CommitmentBank). Какое количество лейблов предложили бы Вы? Почему? Какие лейблы предложили бы Вы (например, числовые, с тегами certainly true, probably true, possibly true, neutral, possibly false, probably false, certainly false или какие-то другие...)? Почему? Подкрепите свое мнение примерами. Предложили бы Вы оценивать комитмент говорящего или субъекта пропозиционального глагола? Или и тот, и другой? Почему? Подкрепите свое мнение примерами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTyP6-2baSic"
   },
   "source": [
    "Мне показалось, что либо нужно уменьшить количество лейблов, либо перевести в числовой вариант (например, сделать шкалу от -50 до 50). В случае с семью лейблами было довольно тяжело понять, куда точно попадает комитмент из-за относительно большого разброса. Было бы достаточно, на мой взгляд, где-то 5 лейблов (2, 1, 0, -1, -2), потому что понять разницу между 2 (или -2) и 1 (или -1) довольно тяжело. Взять к примеру 4 стимул из задания 2. Мне было довольно тяжело определить, в какой степени говорящий боится, но если бы было 5 лейблов, то можно использовать только одну степень неуверенности.\n",
    "\n",
    "В случае же шкалы даётся большой простор, потому что иногда мне хотелось воспользоваться каким-то вещественным промежуточным числом, которое относится, например, немного к 2, но и слегка 3. А шкала как раз позволит не ограничивать себя в таких вещах. Всё в том же 4 стимуле можно было бы поставить число, например, 15, оно бы выражало нужную степень неуверенности.\n",
    "\n",
    "Я бы предложил оценивать комитмент говорящего. В первом случае с помощью него можно попытаться оценить авторитетность говорящего. Например, можно сравнить два высказывания \"Власти понимают, что эффективной поддержкой бизнеса будут субсидии\" и \"Вася понимает, что эффективной поддержкой бизнеса будут субсидии\". В случае с \"властями\" понимается какой-то авторитет, разработанность мер решения проблемы. В случае с Васей не особо понятно, откуда он может понимать решение проблемы, потому тут будет какая-то степень неуверенности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5 (вариант 1)\n",
    "Приведите код для автоматического извлечения стимулов и их аннотации для задания 2 (для русского языка, жанр и ресурс для извлечения можно выбрать любой).\n",
    "\n",
    "Аннотация (источник: https://github.com/mcdm/CommitmentBank):\n",
    "\n",
    "1. Target: sentence of interest, containing a clause-embedding predicate under an entailment canceling operator\n",
    "2. Context: preceding context of the target sentence (up to 2 sentences/turns)\n",
    "3. Prompt: prompt used in the experiment to gather projection judgments\n",
    "4. Verb: clause-embedding predicate\n",
    "5. Embedding: type of entailment canceling operator\n",
    "6. factive: whether the verb is canonically considered factive or not\n",
    "7. MatTense: tense of the matrix verb\n",
    "8. MatSubjLemma: lemma of the matrix verb subject\n",
    "9. MatSubjPer: person of the matrix verb subject\n",
    "10. MatSubjNum: number of the matrix verb subject\n",
    "11. genre: corpus from which the item has been extracted\n",
    "\n",
    "Вы можете предложить свои параметры аннотации (в задании 5, НЕ в задании 2), обосновав свой выбор и подкрепив примерами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе написания кода возникло несколько проблем. Первая - сложность получения prompt. Самое простое решение - это получать регулярным выражением всё, что находится после \"что\". Однако такой подход имеет свои проблемы. Например, в некоторых стимулах отсутствует данный союз. Также возникает проблема в разрешении кореференции, а именно замене одних местоимений на другие, либо же использовании анафоры. Например, предложение \"Катя взяла уголь из мешка. Она не думала, что он пригодится когда-нибудь\", если использовать паттерн, то у prompt получится следующее: \"он пригодится когда-нибудь\". Непонятно, кто он, поэтому нужно заменить на \"уголь\", что уже является проблемой.\n",
    "\n",
    "Вторая проблема - определение MatSubjLemma. В некоторых стимулах получалось так, что в них отсутствует местоимение, есть только предикат. Например, \"Думаю, что не стоит так поступать\". Здесь отсутствует местоимение, что делает затруднительным определение параметра. Однако решение данной проблемы может быть в том, чтобы использовать грамматические признаки предиката и в зависимости от их соотношений проставлять нужное местоимение.\n",
    "\n",
    "Третья проблема - отсутствие какого-либо словаря пропозициональных предикатов. В идеале нужно составить полный список из них, сделать что-то вроде словаря.\n",
    "\n",
    "Четвёртая проблема - выделение нужных комитментов из корпусов. При автоматическом выделении всё-таки довольно тяжело получить нужные предложения с комитментами, потому следует очищать полученные данные. Возможно стоит задавать какие-то параметры поиска необходимых предложений не только по предикату, но и по союзам, связкам \"не\" и т.д. Сделать такой же поиск, как и в НКРЯ. Такое решение позволит минимизировать количество мусорных данных.\n",
    "\n",
    "Остальные параметры можно получить без какого-либо машинного обучения. Попытка реализовать автоматическое извелечение аннотации представлена ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_60xiKzgeu9G",
    "outputId": "9c0c9558-c06c-48c8-e7a7-8718e906e573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: razdel in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: natasha in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: razdel>=0.5.0 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from natasha) (0.9.1)\n",
      "Requirement already satisfied: navec>=0.9.0 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from natasha) (0.10.0)\n",
      "Requirement already satisfied: ipymarkup>=0.8.0 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from natasha) (0.9.0)\n",
      "Requirement already satisfied: yargy>=0.14.0 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from natasha) (0.15.0)\n",
      "Requirement already satisfied: slovnet>=0.3.0 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from navec>=0.9.0->natasha) (1.18.1)\n",
      "Requirement already satisfied: intervaltree>=3 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from ipymarkup>=0.8.0->natasha) (3.0.2)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\users\\adugeen\\anaconda3\\lib\\site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel\n",
    "!pip install pymorphy2\n",
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from razdel import (sentenize, tokenize)\n",
    "from pymystem3 import Mystem\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    PER,\n",
    "    \n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения аннотации\n",
    "def get_annotation(text, verbs):\n",
    "    # Получаем предложения текста\n",
    "    sents = [sent.text for sent in list(sentenize(text))]\n",
    "    \n",
    "    m = Mystem()\n",
    "\n",
    "    # Токенизируем предложения\n",
    "    tokenized_sents = [m.lemmatize(sent) for sent in sents]\n",
    "    \n",
    "    # Находим таргет\n",
    "    target_index = -1\n",
    "    verb = ''\n",
    "    for v in verbs:\n",
    "        target_index = get_target_index(tokenized_sents, v)\n",
    "        if target_index != -1:\n",
    "            verb = v\n",
    "            break\n",
    "    if target_index == -1:\n",
    "        return None\n",
    "    \n",
    "    # Получаем doc, в котором хранится нужная информация по синтаксису\n",
    "    doc = get_doc(sents[target_index])\n",
    "        \n",
    "    context = ' '.join(sents[:target_index])\n",
    "    target = sents[target_index]\n",
    "    verb = get_verb(target, verb)\n",
    "    \n",
    "    # Составляем аннотацию\n",
    "    result = []\n",
    "    result.append(context)\n",
    "    result.append(target)\n",
    "    result.append(verb)\n",
    "    result.append(get_prompt(verb, target))\n",
    "    result.append(get_embeddings(target, verb, doc.sents[0].syntax.tokens))\n",
    "    result.append(is_verb_factive(verb))\n",
    "    result.append(get_verb_category(verb, 'tense'))\n",
    "    result.append(get_subj_pers(doc.sents[0].syntax.tokens))\n",
    "    result.append(get_verb_category(verb, 'number'))\n",
    "    result.append('OpenCorpora')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения индекса таргетового предложения\n",
    "def get_target_index(sents, verb):\n",
    "    for i in range(len(sents)):\n",
    "      if verb in sents[i]:\n",
    "        return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения пропозиционального предиката (ненормализованного)\n",
    "def get_verb(sent, verb):\n",
    "    tokens = [token.text for token in list(tokenize(sent))]\n",
    "    \n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    for token in tokens:\n",
    "        normal_verb = morph.parse(token)[0].normal_form\n",
    "        if normal_verb == verb:\n",
    "            return token\n",
    "    return verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения doc с нужными данными по синтаксису\n",
    "def get_doc(text):\n",
    "    segmenter = Segmenter()\n",
    "\n",
    "    emb = NewsEmbedding()\n",
    "    morph_tagger = NewsMorphTagger(emb)\n",
    "    syntax_parser = NewsSyntaxParser(emb)\n",
    "    ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "\n",
    "    doc = Doc(text)\n",
    "\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    doc.parse_syntax(syntax_parser)\n",
    "    doc.tag_ner(ner_tagger)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения субъекта\n",
    "def get_subj_pers(tokens):\n",
    "    for token in tokens:\n",
    "        if token.rel == 'nsubj':\n",
    "            return token.text\n",
    "    return '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения операторов предложения\n",
    "def get_embeddings(sentence, verb, tokens):\n",
    "    # Список из слов, определяющих условное предложение\n",
    "    cond_unions = ['если']\n",
    "    result = []\n",
    "    # Если в предложении присутствует вопросительный знак, то это вопрос\n",
    "    if '?' in sentence:\n",
    "        result.append('вопрос')\n",
    "    # Если условие содержится в предложении, то это вопрос\n",
    "    for cond in cond_unions:\n",
    "        if cond in sentence:\n",
    "            result.append('условие')\n",
    "    # Если в предложении присутствует модальный глагол, то это модальность\n",
    "    for token in tokens:\n",
    "        if token.rel == 'xcomp':\n",
    "            result.append('модальность')\n",
    "            break\n",
    "    modal = ''\n",
    "    # Определяем модальный глагол\n",
    "    if 'модальность' in result:\n",
    "        for token in tokens:\n",
    "            if token.rel == 'root':\n",
    "                modal = token.text\n",
    "                break\n",
    "    # Определяем отрицание по модальному глаголу (в случае наличия)\n",
    "    if len(re.findall(f'[Нн]е\\s{modal}\\s?.*\\s?{verb}', sentence)) > 0:\n",
    "        result.append('отрицание')\n",
    "    return ', '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения категории пропозиционального предиката\n",
    "def get_verb_category(verb, category):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    tag = morph.parse(verb)[0].tag\n",
    "    \n",
    "    if category == 'tense':\n",
    "        return tag.tense\n",
    "    if category == 'number':\n",
    "        return tag.number\n",
    "    \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция определение фактивности предиката\n",
    "def is_verb_factive(verb):\n",
    "    # Определяем список фактивных глаголов\n",
    "    factive_verbs = ['возмутить', 'огорчить', 'взволновать', 'досадить', 'задеть', \n",
    "             'изумить', 'заинтересовать', 'опечалить', 'подавить',\n",
    "             'поразить', 'прельстить', 'обрадовать', 'смутить', 'жалеть',\n",
    "             'знать', 'узнать', 'признать', 'помнить', 'вспомнить', 'забыть', \n",
    "             'напомнить', 'понимать', 'выяснить', 'осознать', 'проверить',\n",
    "             'видеть', 'показывать', 'объяснить', 'информировать', 'предупредить', 'подтвердить', 'сообщить']\n",
    "\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    normal_form = morph.parse(verb)[0].normal_form\n",
    "    \n",
    "    # Если предикат входит в список, то фактивный\n",
    "    return normal_form in factive_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция получения проективной фразы\n",
    "def get_prompt(verb, sentence):\n",
    "    # Если после предиката есть \"что\", то берём всю фразу до знака препинания\n",
    "    result = re.findall(f'{verb}, что\\s([^?!.,;]+)', sentence)\n",
    " \n",
    "    if len(result) > 0:\n",
    "        return result[0]\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем xml дерево\n",
    "tree = ET.parse('corpora.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список из текстов\n",
    "corpora = []\n",
    "for text in root.iter('text'):\n",
    "    sentences = []\n",
    "    for sentence in text.iter('source'):\n",
    "        sentences.append(sentence.text)\n",
    "    corpora.append(' '.join(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем список пропозициональных предикатов\n",
    "verbs = ['знать', 'думать', 'бояться', 'подозревать', 'думать', \n",
    "         'знать', 'чувствовать', 'понимать', 'надеяться', 'забывать', \n",
    "         'обнаруживать', 'воображать', 'возмутить', 'огорчить', 'взволновать', 'досадить', 'задеть', \n",
    "             'изумить', 'заинтересовать', 'опечалить', 'подавить',\n",
    "             'поразить', 'прельстить', 'обрадовать', 'смутить', 'жалеть',\n",
    "             'знать', 'узнать', 'признать', 'помнить', 'вспомнить', 'забыть', \n",
    "             'напомнить', 'понимать', 'выяснить', 'осознать', 'проверить',\n",
    "             'видеть', 'показывать', 'объяснить', 'информировать', 'предупредить', 'подтвердить', 'сообщить']\n",
    "rows = []\n",
    "cols = ['context', 'target', 'verb', 'prompt', 'embedding', 'factive', 'MatTense', 'MatSubjPers', 'MatSubjNum', 'genre']\n",
    "\n",
    "for text in corpora[:100]:\n",
    "    if len(text) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Получаем аннотацию текста\n",
    "    row = get_annotation(text, verbs)\n",
    "    if row == None:\n",
    "        continue\n",
    "    rows.append(row)\n",
    "    \n",
    "df = pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "      <th>verb</th>\n",
       "      <th>prompt</th>\n",
       "      <th>embedding</th>\n",
       "      <th>factive</th>\n",
       "      <th>MatTense</th>\n",
       "      <th>MatSubjPers</th>\n",
       "      <th>MatSubjNum</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120 тысяч за фотографию Наталья решила действо...</td>\n",
       "      <td>Кто прав в этой истории, а кто виноват — следс...</td>\n",
       "      <td>показывать</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>Кто</td>\n",
       "      <td>None</td>\n",
       "      <td>OpenCorpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Смерть княжны Биография Запись в истории болез...</td>\n",
       "      <td>Больная не отвечала, но была взволнована до слёз.</td>\n",
       "      <td>взволнована</td>\n",
       "      <td></td>\n",
       "      <td>отрицание</td>\n",
       "      <td>True</td>\n",
       "      <td>past</td>\n",
       "      <td>Больная</td>\n",
       "      <td>sing</td>\n",
       "      <td>OpenCorpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11% 11%. 11% Борис Николаевич Ельцин. 19% Иван...</td>\n",
       "      <td>И знаете почему?</td>\n",
       "      <td>знаете</td>\n",
       "      <td></td>\n",
       "      <td>вопрос</td>\n",
       "      <td>True</td>\n",
       "      <td>pres</td>\n",
       "      <td>-</td>\n",
       "      <td>plur</td>\n",
       "      <td>OpenCorpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Он был общепризнанным экспертом по теории заго...</td>\n",
       "      <td>«Рад видеть вас здесь, леди, джентльмены и нарки.</td>\n",
       "      <td>видеть</td>\n",
       "      <td></td>\n",
       "      <td>модальность</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>None</td>\n",
       "      <td>OpenCorpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He-man, Папа Хэм. Короткие, рубленые фразы в д...</td>\n",
       "      <td>Было кого жалеть, над кем плакать, кому сочувс...</td>\n",
       "      <td>жалеть</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>None</td>\n",
       "      <td>OpenCorpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001—2010-й: книги, которые потрясали На арене...</td>\n",
       "      <td>Цитата: «А войну за сбыты Набокова в южной Мос...</td>\n",
       "      <td>помнишь</td>\n",
       "      <td></td>\n",
       "      <td>вопрос</td>\n",
       "      <td>True</td>\n",
       "      <td>pres</td>\n",
       "      <td>-</td>\n",
       "      <td>sing</td>\n",
       "      <td>OpenCorpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Дзига Вертов . Ловец звуков , или Доктор Франк...</td>\n",
       "      <td>Он выстраивал из звуков и созвучий стихотворны...</td>\n",
       "      <td>понимал</td>\n",
       "      <td></td>\n",
       "      <td>отрицание</td>\n",
       "      <td>True</td>\n",
       "      <td>past</td>\n",
       "      <td>Он</td>\n",
       "      <td>sing</td>\n",
       "      <td>OpenCorpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80 лет национальной трагедии Никаких документо...</td>\n",
       "      <td>А по дороге снова начинает рассказывать истори...</td>\n",
       "      <td>показывать</td>\n",
       "      <td></td>\n",
       "      <td>модальность</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>-</td>\n",
       "      <td>None</td>\n",
       "      <td>OpenCorpora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Крах целой отрасли начался без паники . За 2 с...</td>\n",
       "      <td>Теперь вы знаете , с какой скоростью умирают б...</td>\n",
       "      <td>знаете</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>pres</td>\n",
       "      <td>вы</td>\n",
       "      <td>plur</td>\n",
       "      <td>OpenCorpora</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  120 тысяч за фотографию Наталья решила действо...   \n",
       "1  Смерть княжны Биография Запись в истории болез...   \n",
       "2  11% 11%. 11% Борис Николаевич Ельцин. 19% Иван...   \n",
       "3  Он был общепризнанным экспертом по теории заго...   \n",
       "4  He-man, Папа Хэм. Короткие, рубленые фразы в д...   \n",
       "5  2001—2010-й: книги, которые потрясали На арене...   \n",
       "6  Дзига Вертов . Ловец звуков , или Доктор Франк...   \n",
       "7  80 лет национальной трагедии Никаких документо...   \n",
       "8  Крах целой отрасли начался без паники . За 2 с...   \n",
       "\n",
       "                                              target         verb prompt  \\\n",
       "0  Кто прав в этой истории, а кто виноват — следс...   показывать          \n",
       "1  Больная не отвечала, но была взволнована до слёз.  взволнована          \n",
       "2                                   И знаете почему?       знаете          \n",
       "3  «Рад видеть вас здесь, леди, джентльмены и нарки.       видеть          \n",
       "4  Было кого жалеть, над кем плакать, кому сочувс...       жалеть          \n",
       "5  Цитата: «А войну за сбыты Набокова в южной Мос...      помнишь          \n",
       "6  Он выстраивал из звуков и созвучий стихотворны...      понимал          \n",
       "7  А по дороге снова начинает рассказывать истори...   показывать          \n",
       "8  Теперь вы знаете , с какой скоростью умирают б...       знаете          \n",
       "\n",
       "     embedding  factive MatTense MatSubjPers MatSubjNum        genre  \n",
       "0                  True     None         Кто       None  OpenCorpora  \n",
       "1    отрицание     True     past     Больная       sing  OpenCorpora  \n",
       "2       вопрос     True     pres           -       plur  OpenCorpora  \n",
       "3  модальность     True     None           -       None  OpenCorpora  \n",
       "4                  True     None           -       None  OpenCorpora  \n",
       "5       вопрос     True     pres           -       sing  OpenCorpora  \n",
       "6    отрицание     True     past          Он       sing  OpenCorpora  \n",
       "7  модальность     True     None           -       None  OpenCorpora  \n",
       "8                  True     pres          вы       plur  OpenCorpora  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
